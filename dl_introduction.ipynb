{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import src.point_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "target_slope_val = 3.5\n",
    "xy = src.point_data.generate_center_line_points(\n",
    "    m_mu=target_slope_val,\n",
    "    m_std=1.0,\n",
    "    num_pts=100\n",
    ")\n",
    "\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.axvline(0, color=\"black\")\n",
    "\n",
    "plt.axline((0, 0), slope=target_slope_val, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = torch.FloatTensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(slope_param, xy):\n",
    "    return torch.sum(torch.square(xy[:, 1] - (slope_param * xy[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_val_arr = numpy.linspace(-100, 100, 1000)\n",
    "slope_val_loss_list = []\n",
    "\n",
    "for slope_val in slope_val_arr:\n",
    "    slope_param[0] = slope_val\n",
    "    slope_val_loss_list.append(compute_loss(slope_param, xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.plot(slope_val_arr, slope_val_loss_list)\n",
    "\n",
    "plt.xlabel(\"Line slope\")\n",
    "plt.ylabel(\"Line loss\")\n",
    "\n",
    "plt.axvline(target_slope_val, color=\"red\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = torch.nn.Parameter(torch.FloatTensor([0]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    params=(slope_param,),\n",
    "    lr=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = compute_loss(slope_param, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = torch.nn.Parameter(torch.FloatTensor([0]), requires_grad=True)\n",
    "\n",
    "# 0.02\n",
    "# 0.03\n",
    "# 0.035\n",
    "# 0.0325\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=(slope_param,),\n",
    "    lr=0.0325\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "training_slope_list = []\n",
    "training_loss_list = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "\n",
    "    loss = compute_loss(slope_param, xy)\n",
    "    loss.backward()\n",
    "\n",
    "    training_slope_list.append(slope_param.item())\n",
    "    training_loss_list.append(loss.item())\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "#\n",
    "\n",
    "loss = compute_loss(slope_param, xy)\n",
    "\n",
    "training_slope_list.append(slope_param.item())\n",
    "training_loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.plot(slope_val_arr, slope_val_loss_list)\n",
    "\n",
    "plt.plot(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"Loss Curve\"\n",
    ")\n",
    "\n",
    "cmap_name = \"plasma\"\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=numpy.asarray([\n",
    "        mpl.colormaps.get_cmap(cmap_name)(x)\n",
    "        for x in numpy.linspace(0, 1, len(training_slope_list))\n",
    "    ]),\n",
    "    edgecolor=\"black\",\n",
    "    s=100,\n",
    "    label=\"Training Epochs\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Line slope\")\n",
    "plt.ylabel(\"Line loss\")\n",
    "\n",
    "plt.axvline(target_slope_val, color=\"red\")\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=mpl.colormaps.get_cmap(cmap_name))\n",
    "sm.set_clim(vmin=0, vmax=num_epochs)\n",
    "\n",
    "plt.colorbar(\n",
    "    sm,\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#plt.xlim(-5, 15)\n",
    "#plt.ylim(0, 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final loss: {:.2e}\".format(training_loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.axvline(0, color=\"black\")\n",
    "\n",
    "plt.axline((0, 0), slope=slope_param.item(), color=\"red\")\n",
    "plt.axline((0, 0), slope=target_slope_val, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = torch.nn.Parameter(torch.FloatTensor([0]), requires_grad=True)\n",
    "\n",
    "# 0.02\n",
    "# 0.03\n",
    "# 0.05\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=(slope_param,),\n",
    "    lr=0.05\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer,\n",
    "    gamma=0.9\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "training_slope_list = []\n",
    "training_lr_list = []\n",
    "training_loss_list = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    \n",
    "    loss = compute_loss(slope_param, xy)\n",
    "    loss.backward()\n",
    "\n",
    "    training_slope_list.append(slope_param.item())\n",
    "    training_loss_list.append(loss.item())\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    training_lr_list.append(scheduler.get_last_lr())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "#\n",
    "\n",
    "loss = compute_loss(slope_param, xy)\n",
    "\n",
    "training_slope_list.append(slope_param.item())\n",
    "training_loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(training_lr_list, \"-o\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.plot(slope_val_arr, slope_val_loss_list)\n",
    "\n",
    "plt.plot(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"Loss Curve\"\n",
    ")\n",
    "\n",
    "cmap_name = \"plasma\"\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=numpy.asarray([\n",
    "        mpl.colormaps.get_cmap(cmap_name)(x)\n",
    "        for x in numpy.linspace(0, 1, len(training_slope_list))\n",
    "    ]),\n",
    "    edgecolor=\"black\",\n",
    "    s=100,\n",
    "    label=\"Training Epochs\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Line slope\")\n",
    "plt.ylabel(\"Line loss\")\n",
    "\n",
    "plt.axvline(target_slope_val, color=\"red\")\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=mpl.colormaps.get_cmap(cmap_name))\n",
    "sm.set_clim(vmin=0, vmax=num_epochs)\n",
    "\n",
    "plt.colorbar(\n",
    "    sm,\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#plt.xlim(-5, 15)\n",
    "#plt.ylim(0, 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final loss: {:.2e}\".format(training_loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.axvline(0, color=\"black\")\n",
    "\n",
    "plt.axline((0, 0), slope=slope_param.item(), color=\"red\")\n",
    "plt.axline((0, 0), slope=target_slope_val, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop with Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_batch_list = torch.split(xy, 10, dim=0)\n",
    "\n",
    "print(len(xy_batch_list))\n",
    "for xy_batch in xy_batch_list:\n",
    "    print(xy_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_param = torch.nn.Parameter(torch.FloatTensor([0]), requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=(slope_param,),\n",
    "    lr=0.035 * 10\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer,\n",
    "    gamma=0.9\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "training_slope_list = []\n",
    "training_lr_list = []\n",
    "training_loss_list = []\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 10\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        epoch_total_loss = 0\n",
    "\n",
    "        for xy_batch in torch.split(xy, batch_size, dim=0):\n",
    "            loss = compute_loss(slope_param, xy_batch)\n",
    "            epoch_total_loss += loss.item()\n",
    "        \n",
    "    training_slope_list.append(slope_param.item())\n",
    "    training_loss_list.append(epoch_total_loss)\n",
    "\n",
    "    #\n",
    "\n",
    "    for xy_batch in torch.split(xy, batch_size, dim=0):\n",
    "\n",
    "        loss = compute_loss(slope_param, xy_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    training_lr_list.append(scheduler.get_last_lr())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "#\n",
    "\n",
    "final_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xy_batch in torch.split(xy, batch_size, dim=0):\n",
    "        loss = compute_loss(slope_param, xy_batch)\n",
    "        final_loss += loss.item()\n",
    "\n",
    "training_slope_list.append(slope_param.item())\n",
    "training_loss_list.append(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(training_lr_list, \"-o\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.plot(slope_val_arr, slope_val_loss_list)\n",
    "\n",
    "plt.plot(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"Loss Curve\"\n",
    ")\n",
    "\n",
    "cmap_name = \"plasma\"\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    training_slope_list,\n",
    "    training_loss_list,\n",
    "    color=numpy.asarray([\n",
    "        mpl.colormaps.get_cmap(cmap_name)(x)\n",
    "        for x in numpy.linspace(0, 1, len(training_slope_list))\n",
    "    ]),\n",
    "    edgecolor=\"black\",\n",
    "    s=100,\n",
    "    label=\"Training Epochs\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Line slope\")\n",
    "plt.ylabel(\"Line loss\")\n",
    "\n",
    "plt.axvline(target_slope_val, color=\"red\")\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=mpl.colormaps.get_cmap(cmap_name))\n",
    "sm.set_clim(vmin=0, vmax=num_epochs)\n",
    "\n",
    "plt.colorbar(\n",
    "    sm,\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#plt.xlim(-5, 15)\n",
    "#plt.ylim(0, 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final loss: {:.2e}\".format(training_loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.axvline(0, color=\"black\")\n",
    "\n",
    "plt.axline((0, 0), slope=slope_param.item(), color=\"red\")\n",
    "plt.axline((0, 0), slope=target_slope_val, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2cb538239ff5792ab8489b2aec6ee5c264edcebfa0e19cb03b1021ec9f17cac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
